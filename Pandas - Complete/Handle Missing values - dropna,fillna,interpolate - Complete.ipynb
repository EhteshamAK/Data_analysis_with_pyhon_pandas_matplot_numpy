{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b447f6",
   "metadata": {},
   "source": [
    "# Handle missing values in dataset using dropna(),fillna(),interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6db6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import   libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8f17de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Pc World Computers\\\\Desktop\\\\Pandas - Complete\\\\students grade.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PCWORL~1\\AppData\\Local\\Temp/ipykernel_1276/3309783404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Pc World Computers\\Desktop\\Pandas - Complete\\students grade.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Pc World Computers\\\\Desktop\\\\Pandas - Complete\\\\students grade.xlsx'"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_excel(r\"C:\\Users\\Pc World Computers\\Desktop\\Pandas - Complete\\students grade.xlsx\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af26748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the data set\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the data set\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb007a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details about the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the null/missing values in dataset\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d156ac",
   "metadata": {},
   "source": [
    "#### There are multiple ways to deal with missing values. At first, we will create a copy of the dataset and then we will use *dropna()*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431ca5e",
   "metadata": {},
   "source": [
    "### dropna() is used to drop all the values in the columns that has missing or nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6520d35",
   "metadata": {},
   "source": [
    "# dropna() - drop all the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will create the copy of the dataset\n",
    "dataset_copy1 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22324d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f865ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the rows with missing values\n",
    "dataset_copy1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf3535",
   "metadata": {},
   "source": [
    "All the rows with missing values has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a64fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aecc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will export this dataset in excel\n",
    "dataset_copy1.to_excel(\"Handle Missing values with dropna.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6b1b2",
   "metadata": {},
   "source": [
    "This method is handy for large dataset,In the smaller dataset this function is not very useful. It will drop all the values that has missing or nan values. There are other better options we could use on smaller dataset like fillna(),interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e24c15",
   "metadata": {},
   "source": [
    "# fillna() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d8ecf",
   "metadata": {},
   "source": [
    "### fillna() is used for handling missing values or nan values in the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cbc61",
   "metadata": {},
   "source": [
    "#### We can use fillna() for handling numercial missing data with different techniques like by putting average values(mean),median,mode etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32deab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a  copy of the dataset\n",
    "dataset_copy2 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be7d8f",
   "metadata": {},
   "source": [
    "Handle missing value with **fillna()** by average value(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2[\"Math\"].fillna(dataset_copy2[\"Math\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b483427",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2[\"English\"].fillna(dataset_copy2[\"English\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2[\"Science\"].fillna(dataset_copy2[\"Science\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ada82b",
   "metadata": {},
   "source": [
    "Data is clean now with inseting average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03687c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49caf358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data type\n",
    "dataset_copy2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the datatype to int of columns: Math,English,Science\n",
    "dataset_copy2[[\"Math\",\"English\",\"Science\"]] = dataset_copy2[[\"Math\",\"English\",\"Science\"]].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the datatype after manipulation\n",
    "dataset_copy2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e11f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the dataset manipulated by fillna() with average value\n",
    "dataset_copy2.to_csv(\"Handle missing data with fillan(mean()).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85f556",
   "metadata": {},
   "source": [
    "# fillna() - method=bfill/pad,ffill - limit=1 (could be 1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a duplicate  of the original dataset\n",
    "dataset_copy3 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5889b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e9a82",
   "metadata": {},
   "source": [
    "handle missing data with forward or backward values present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy3.ffill(limit=2,inplace=True) # limit means it can only fill the value in next 2 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d4720",
   "metadata": {},
   "source": [
    "#### The data is handled by ffill - forward fill which insert the row 3  value to row 4,5  in the next column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3774989",
   "metadata": {},
   "source": [
    "## Same could be done using bfill or pad - dataset_copy3.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the dataset into excel\n",
    "dataset_copy3.to_excel(\"fillna with ffill,limit.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9e9ed",
   "metadata": {},
   "source": [
    "### handling missing values with dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3218ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the original dataset\n",
    "dataset_copy4 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b23dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209140da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing data in dictionary \n",
    "dataset_copy4.fillna({\n",
    "    'Math': 50,\n",
    "    'Science':50,\n",
    "    'English':50\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce483757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the dataset\n",
    "dataset_copy4.to_excel(\"fillna with dictionary.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fccf6",
   "metadata": {},
   "source": [
    "# interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934392e5",
   "metadata": {},
   "source": [
    "### --- interpolate() is used different methods to insert value in the missing columns by default its method is linear, it could be time, nearest,bfill,ffill,pad etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddee3d",
   "metadata": {},
   "source": [
    "> for example, row 5 is nan/missing and we want a value in it. Then we could use  interpolate() to insert values, by default linear method it will add the average value of row 6 and row 4 to the missing field. By time method it will use the neares time,date etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the original dataset\n",
    "dataset_copy5 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf709b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to handle these values by interpolate()  with linear method.\n",
    "dataset_copy5.interpolate(inplace=True) # linear is used for continous values time works well on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f91615",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy5.to_excel('interpolate.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
